{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    RNA Alignment Assignment\n",
    "    \n",
    "    Implement each of the functions below using the algorithms covered in class.\n",
    "    You can construct additional functions and data structures but you should not\n",
    "    change the functions' APIs.\n",
    "\n",
    "    You will be graded on the helper function implementations as well as the RNA alignment, although\n",
    "    you do not have to use your helper function.\n",
    "    \n",
    "    *** Make sure to comment out any print statement so as not to interfere with the grading script\n",
    "\"\"\"\n",
    "\n",
    "import sys # DO NOT EDIT THIS\n",
    "from shared import *\n",
    "\n",
    "import time\n",
    "\n",
    "ALPHABET = [TERMINATOR] + BASES\n",
    "\n",
    "def get_suffix_array(s):\n",
    "    \"\"\"\n",
    "    Naive implementation of suffix array generation (0-indexed). You do not have to implement the\n",
    "    KS Algorithm. Make this code fast enough so you have enough time in Aligner.__init__ (see bottom).\n",
    "\n",
    "    Input:\n",
    "        s: a string of the alphabet ['A', 'C', 'G', 'T'] already terminated by a unique delimiter '$'\n",
    "    \n",
    "    Output: list of indices representing the suffix array\n",
    "\n",
    "    >>> get_suffix_array('GATAGACA$')\n",
    "    [8, 7, 5, 3, 1, 6, 4, 0, 2]\n",
    "    \"\"\"\n",
    "    def compare(i, j):\n",
    "        c = 0\n",
    "        while s[i + c] == s[j + c]:\n",
    "            c += 1\n",
    "        if s[i + c] > s[j + c]:\n",
    "            return 1\n",
    "        elif s[i + c] < s[j + c]:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    suffixes = sorted(range(len(s)), cmp=compare)\n",
    "    return suffixes\n",
    "\n",
    "def get_bwt(s, sa):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        s: a string terminated by a unique delimiter '$'\n",
    "        sa: the suffix array of s\n",
    "\n",
    "    Output:\n",
    "        L: BWT of s as a string\n",
    "    \"\"\"\n",
    "    return ''.join([s[i-1] for i in sa])\n",
    "\n",
    "def get_F(L):\n",
    "    \"\"\"\n",
    "    Input: L = get_bwt(s)\n",
    "\n",
    "    Output: F, first column in Pi_sorted\n",
    "    \"\"\"\n",
    "    return ''.join(sorted(list(L)))\n",
    "\n",
    "def get_M(F):\n",
    "    \"\"\"\n",
    "    Returns the helper data structure M (using the notation from class). M is a dictionary that maps character\n",
    "    strings to start indices. i.e. M[c] is the first occurrence of \"c\" in F.\n",
    "\n",
    "    If a character \"c\" does not exist in F, you may set M[c] = -1\n",
    "    \"\"\"\n",
    "    M = {}\n",
    "    for i in range(len(F)):\n",
    "        char = F[i]\n",
    "        if char not in M:\n",
    "            M[char] = i\n",
    "    for char in ALPHABET:\n",
    "        if char not in M:\n",
    "            M[char] = -1\n",
    "    return M\n",
    "\n",
    "def get_occ(L):\n",
    "    \"\"\"\n",
    "    Returns the helper data structure OCC (using the notation from class). OCC should be a dictionary that maps \n",
    "    string character to a list of integers. If c is a string character and i is an integer, then OCC[c][i] gives\n",
    "    the number of occurrences of character \"c\" in the bwt string up to and including index i\n",
    "    \"\"\"\n",
    "    occ = {i: [0] for i in ALPHABET}\n",
    "    for i in L:\n",
    "        for j in occ:\n",
    "            if i != j:\n",
    "                occ[j].append(occ[j][-1])\n",
    "            else:\n",
    "                occ[i].append(occ[i][-1]+1)\n",
    "    for i in occ:\n",
    "        occ[i].pop(0)\n",
    "    return occ\n",
    "\n",
    "def construct_L(M, occ):\n",
    "    length = 0\n",
    "    for char in occ:\n",
    "        length += occ[char][-1]\n",
    "    L = ['']*length\n",
    "    for char in occ:\n",
    "        for i in range(occ[char][-1]):\n",
    "            L[occ[char].index(i+1)] = char\n",
    "    return ''.join(L)\n",
    "    \n",
    "def exact_suffix_matches(p, M, occ):\n",
    "    \"\"\"\n",
    "    Find the positions within the suffix array sa of the longest possible suffix of p \n",
    "    that is a substring of s (the original string).\n",
    "    \n",
    "    Note that such positions must be consecutive, so we want the range of positions.\n",
    "\n",
    "    Input:\n",
    "        p: the pattern string\n",
    "        M, occ: buckets and repeats information used by sp, ep\n",
    "\n",
    "    Output: a tuple (range, length)\n",
    "        range: a tuple (start inclusive, end exclusive) of the indices in sa that contains\n",
    "            the longest suffix of p as a prefix. range=None if no indices matches any suffix of p\n",
    "        length: length of the longest suffix of p found in s. length=0 if no indices matches any suffix of p\n",
    "\n",
    "        An example return value would be ((2, 5), 7). This means that p[len(p) - 7 : len(p)] is\n",
    "        found in s and matches positions 2, 3, and 4 in the suffix array.\n",
    "\n",
    "    >>> s = 'ACGT' * 10 + '$'\n",
    "    >>> sa = get_suffix_array(s)\n",
    "    >>> sa\n",
    "    [40, 36, 32, 28, 24, 20, 16, 12, 8, 4, 0, 37, 33, 29, 25, 21, 17, 13, 9, 5, 1, 38, 34, 30, 26, 22, 18, 14, 10, 6, 2, 39, 35, 31, 27, 23, 19, 15, 11, 7, 3]\n",
    "    >>> L = get_bwt(s, sa)\n",
    "    >>> L\n",
    "    'TTTTTTTTTT$AAAAAAAAAACCCCCCCCCCGGGGGGGGGG'\n",
    "    >>> F = get_F(L)\n",
    "    >>> F\n",
    "    '$AAAAAAAAAACCCCCCCCCCGGGGGGGGGGTTTTTTTTTT'\n",
    "    >>> M = get_M(F)\n",
    "    >>> sorted(M.items())\n",
    "    [('$', 0), ('A', 1), ('C', 11), ('G', 21), ('T', 31)]\n",
    "    >>> occ = get_occ(L)\n",
    "    >>> type(occ) == dict, type(occ['$']) == list, type(occ['$'][0]) == int\n",
    "    (True, True, True)\n",
    "    >>> occ['$']\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    >>> exact_suffix_matches('ACTGA', M, occ)\n",
    "    ((1, 11), 1)\n",
    "    >>> exact_suffix_matches('$', M, occ)\n",
    "    ((0, 1), 1)\n",
    "    >>> exact_suffix_matches('AA', M, occ)\n",
    "    ((1, 11), 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize sp, ep\n",
    "    length = len(p)\n",
    "    last_char = p[-1]\n",
    "    sp = M[last_char]\n",
    "    if sp == -1:\n",
    "        return (None, 0)\n",
    "    \n",
    "    # find next(last_char)\n",
    "    nxt = float('inf')\n",
    "    nxt_item = None\n",
    "    for item in M:\n",
    "        if nxt > M[item] > M[last_char] and item != last_char:\n",
    "            nxt = M[item]\n",
    "            nxt_item = item\n",
    "    if nxt_item == None:\n",
    "        ep = len(occ['$']) - 1\n",
    "    else:\n",
    "        ep = nxt - 1\n",
    "    \n",
    "    # changed for loop a bit, only works on strings len >= 2\n",
    "    # for strings of len 1, it skips to the end and works\n",
    "    for i in range(length-2,-1,-1):\n",
    "        sp_ph = M[p[i]] + occ[p[i]][sp-1]\n",
    "        ep_ph = M[p[i]] + occ[p[i]][ep]-1\n",
    "        if sp_ph > ep_ph:\n",
    "            return ((sp,ep+1),length-i-1)\n",
    "        sp = sp_ph\n",
    "        ep = ep_ph\n",
    "    return ((sp,ep+1), length)\n",
    "\n",
    "def bowtie(p, M, occ):\n",
    "    L = construct_L(M, occ)\n",
    "    num_mismatches = 0\n",
    "    length = len(p)\n",
    "    last_char = p[-1]\n",
    "    sp = M[last_char]\n",
    "    if sp == -1:\n",
    "        return (None, 0)\n",
    "    \n",
    "    # find next(last_char)\n",
    "    nxt = float('inf')\n",
    "    nxt_item = None\n",
    "    for item in M:\n",
    "        if nxt > M[item] > M[last_char] and item != last_char:\n",
    "            nxt = M[item]\n",
    "            nxt_item = item\n",
    "    if nxt_item == None:\n",
    "        ep = len(occ['$']) - 1\n",
    "    else:\n",
    "        ep = nxt - 1\n",
    "    \n",
    "    # changed for loop a bit, only works on strings len >= 2\n",
    "    # for strings of len 1, it skips to the end and works\n",
    "    for i in range(length-2,-1,-1):\n",
    "        sp_ph = M[p[i]] + occ[p[i]][sp-1]\n",
    "        ep_ph = M[p[i]] + occ[p[i]][ep]-1\n",
    "\n",
    "        ptr = ep\n",
    "        is_mismatch = False\n",
    "        while sp_ph > ep_ph and ptr >= ep:\n",
    "            new_char = L[ptr]\n",
    "            sp_ph = M[new_char] + occ[new_char][sp-1]\n",
    "            ep_ph = M[new_char] + occ[new_char][ep]-1\n",
    "            ptr -= 1\n",
    "            is_mismatch = True\n",
    "\n",
    "        num_mismatches += is_mismatch\n",
    "        sp = sp_ph\n",
    "        ep = ep_ph\n",
    "\n",
    "    return ((sp,ep+1), length, num_mismatches)\n",
    "\n",
    "MIN_INTRON_SIZE = 20\n",
    "MAX_INTRON_SIZE = 10000\n",
    "\n",
    "class Aligner: \n",
    "    def __init__(self, genome_sequence, known_genes):\n",
    "        \"\"\"\n",
    "        Initializes the aligner. Do all time intensive set up here. i.e. build suffix array.\n",
    "\n",
    "        genome_sequence: a string (NOT TERMINATED BY '$') representing the bases of the of the genome\n",
    "        known_genes: a python set of Gene objects (see shared.py) that represent known genes. You can get the isoforms \n",
    "                     and exons from a Gene object\n",
    "\n",
    "        Time limit: 500 seconds maximum on the provided data. Note that our server is probably faster than your machine, \n",
    "                    so don't stress if you are close. Server is 1.25 times faster than the i7 CPU on my computer\n",
    "\n",
    "        \"\"\"\n",
    "        last_time = time.time()\n",
    "        self.genome_sa = get_suffix_array(genome_sequence)\n",
    "        self.genome_L = get_bwt(genome_sequence, self.genome_sa)\n",
    "        self.genome_M = get_M(get_F(self.genome_L))\n",
    "        self.genome_occ = get_occ(self.genome_L)\n",
    "        \n",
    "        print('FM index of genome: ' + str(time.time() - last_time))\n",
    "        last_time = time.time()\n",
    "        \n",
    "        isos_sa = {}\n",
    "        isos_L = {}\n",
    "        isos_M = {}\n",
    "        isos_occ = {}\n",
    "#         known_genes = []\n",
    "\n",
    "#         with open('genes.tab') as f:\n",
    "#             curr = f.readline().split()\n",
    "#             gene_id = curr[1]\n",
    "#             isoforms = []\n",
    "#             while curr:\n",
    "#                 if curr[0] == 'gene':\n",
    "#                     known_genes.append(Gene(gene_id, isoforms))\n",
    "#                     gene_id = curr[1]\n",
    "#                     isoforms = []\n",
    "#                 elif curr[1] == 'isoform':\n",
    "#                     isoforms.append(Isoform(isoform_id, exons))\n",
    "#                     isoform_id = curr[1]\n",
    "#                     exons = []\n",
    "#                 else:\n",
    "#                     exons.append([Exon(curr[1],curr[2],curr[3])])\n",
    "        \n",
    "        last_time = time.time()\n",
    "        \n",
    "        iso_names = []\n",
    "        for gene in known_genes:\n",
    "            for isoform in gene.isoforms:\n",
    "                iso_names.append(isoform.id)\n",
    "                spliced_isoform = ''\n",
    "                i = isoform.id\n",
    "                for exon in isoform.exons:\n",
    "                    exon_str = genome_sequence[exon.start:exon.end]\n",
    "                    spliced_isoform += exon_str\n",
    "                spliced_isoform += '$'\n",
    "                isos_sa[i] = get_suffix_array(spliced_isoform)\n",
    "                isos_L[i] = get_bwt(spliced_isoform, isos_sa[i])\n",
    "                isos_M[i] = get_M(get_F(isos_L[i]))\n",
    "                isos_occ[i] = get_occ(isos_L[i])\n",
    "                print('FM index of isoform, length %d: ' % len(spliced_isoform) + str(time.time() - last_time))\n",
    "                last_time = time.time()\n",
    "        \n",
    "        self.isos_sa = isos_sa\n",
    "        self.isos_L = isos_L\n",
    "        self.isos_M = isos_M\n",
    "        self.isos_occ = isos_occ\n",
    "        self.iso_names = iso_names\n",
    "\n",
    "    def align(self, read_sequence):\n",
    "        \"\"\"\n",
    "        Returns an alignment to the genome sequence. An alignment is a list of pieces. \n",
    "        Each piece consists of a start index in the read, a start index in the genome, and a length \n",
    "        indicating how many bases are aligned in this piece. Note that mismatches are count as \"aligned\".\n",
    "\n",
    "        Note that <read_start_2> >= <read_start_1> + <length_1>. If your algorithm produces an alignment that \n",
    "        violates this, we will remove pieces from your alignment arbitrarily until consecutive pieces \n",
    "        satisfy <read_start_2> >= <read_start_1> + <length_1>\n",
    "\n",
    "        Return value must be in the form (also see the project pdf):\n",
    "        [(<read_start_1>, <reference_start_1, length_1), (<read_start_2>, <reference_start_2, length_2), ...]\n",
    "\n",
    "        If no good matches are found: return the best match you can find or return []\n",
    "\n",
    "        Time limit: 0.5 seconds per read on average on the provided data.\n",
    "        \"\"\"\n",
    "        \n",
    "        # bowtie, read to isoforms\n",
    "        for iso_name in self.iso_names:\n",
    "            # find inexact matches\n",
    "            matches = bowtie(read_sequence, self.isos_M[iso_name], self.isos_occ[iso_name])\n",
    "            print(matches)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM index of genome: 10.072603941\n",
      "FM index of isoform, length 576: 0.00404000282288\n",
      "FM index of isoform, length 266: 0.0015811920166\n",
      "FM index of isoform, length 311: 0.00204110145569\n",
      "FM index of isoform, length 466: 0.00286602973938\n"
     ]
    }
   ],
   "source": [
    "with open('bases_small.txt') as f:\n",
    "    start = 852\n",
    "    exon1 = Exon('E1', start, start + 10)\n",
    "    exon2 = Exon('E2', start + 423, start + 588)\n",
    "    exon3 = Exon('E3', start + 588, start + 688)\n",
    "    exon4 = Exon('E4', start + 700, start + 1000)\n",
    "    iso1 = Isoform('I1', [exon1, exon2, exon3, exon4])\n",
    "    iso2 = Isoform('I2', [exon2, exon3])\n",
    "    iso3 = Isoform('I3', [exon1, exon4])\n",
    "    iso4 = Isoform('I4', [exon2, exon4])\n",
    "    gene = Gene('G1', [iso1, iso2, iso3, iso4])\n",
    "    \n",
    "    a = Aligner(f.read(), [gene])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((128, 129), 90, 1)\n",
      "((58, 59), 90, 1)\n",
      "((266, 267), 90, 68)\n",
      "((107, 108), 90, 1)\n"
     ]
    }
   ],
   "source": [
    "a.align('ATTAGCTTTCTCTGGTGCCCAGAAGGGTCAAGACAGCGAGCCAGAGGCATTCCCGAGGTCTCACCGTTATCAATGGGTAGTCACCAGTGC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
