{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    RNA Alignment Assignment\n",
    "    \n",
    "    Implement each of the functions below using the algorithms covered in class.\n",
    "    You can construct additional functions and data structures but you should not\n",
    "    change the functions' APIs.\n",
    "\n",
    "    You will be graded on the helper function implementations as well as the RNA alignment, although\n",
    "    you do not have to use your helper function.\n",
    "    \n",
    "    *** Make sure to comment out any print statement so as not to interfere with the grading script\n",
    "\"\"\"\n",
    "\n",
    "import sys # DO NOT EDIT THIS\n",
    "from shared import *\n",
    "\n",
    "ALPHABET = [TERMINATOR] + BASES\n",
    "\n",
    "def get_suffix_array(s):\n",
    "    \"\"\"\n",
    "    Naive implementation of suffix array generation (0-indexed). You do not have to implement the\n",
    "    KS Algorithm. Make this code fast enough so you have enough time in Aligner.__init__ (see bottom).\n",
    "\n",
    "    Input:\n",
    "        s: a string of the alphabet ['A', 'C', 'G', 'T'] already terminated by a unique delimiter '$'\n",
    "    \n",
    "    Output: list of indices representing the suffix array\n",
    "\n",
    "    >>> get_suffix_array('GATAGACA$')\n",
    "    [8, 7, 5, 3, 1, 6, 4, 0, 2]\n",
    "    \"\"\"\n",
    "    suffixes = [(s[i:], i) for i in range(len(s))]\n",
    "    suffixes = sorted(suffixes)\n",
    "    return [i[1] for i in suffixes]\n",
    "\n",
    "def get_bwt(s, sa):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        s: a string terminated by a unique delimiter '$'\n",
    "        sa: the suffix array of s\n",
    "\n",
    "    Output:\n",
    "        L: BWT of s as a string\n",
    "    \"\"\"\n",
    "    return ''.join([s[i-1] for i in sa])\n",
    "\n",
    "def get_F(L):\n",
    "    \"\"\"\n",
    "    Input: L = get_bwt(s)\n",
    "\n",
    "    Output: F, first column in Pi_sorted\n",
    "    \"\"\"\n",
    "    return ''.join(sorted(list(L)))\n",
    "\n",
    "def get_M(F):\n",
    "    \"\"\"\n",
    "    Returns the helper data structure M (using the notation from class). M is a dictionary that maps character\n",
    "    strings to start indices. i.e. M[c] is the first occurrence of \"c\" in F.\n",
    "\n",
    "    If a character \"c\" does not exist in F, you may set M[c] = -1\n",
    "    \"\"\"\n",
    "    M = {}\n",
    "    for i in range(len(F)):\n",
    "        char = F[i]\n",
    "        if char not in M:\n",
    "            M[char] = i\n",
    "    for char in ALPHABET:\n",
    "        if char not in M:\n",
    "            M[char] = -1\n",
    "    return M\n",
    "\n",
    "def get_occ(L):\n",
    "    \"\"\"\n",
    "    Returns the helper data structure OCC (using the notation from class). OCC should be a dictionary that maps \n",
    "    string character to a list of integers. If c is a string character and i is an integer, then OCC[c][i] gives\n",
    "    the number of occurrences of character \"c\" in the bwt string up to and including index i\n",
    "    \"\"\"\n",
    "    occ = {i: [0] for i in ALPHABET}\n",
    "    for i in L:\n",
    "        for j in occ:\n",
    "            if i != j:\n",
    "                occ[j].append(occ[j][-1])\n",
    "            else:\n",
    "                occ[i].append(occ[i][-1]+1)\n",
    "    for i in occ:\n",
    "        occ[i].pop(0)\n",
    "    return occ\n",
    "\n",
    "def construct_L(M, occ):\n",
    "    length = 0\n",
    "    for char in occ:\n",
    "        length += occ[char][-1]\n",
    "    L = ['']*length\n",
    "    for char in occ:\n",
    "        for i in range(occ[char][-1]):\n",
    "            L[occ[char].index(i+1)] = char\n",
    "    return ''.join(L)\n",
    "    \n",
    "def exact_suffix_matches(p, M, occ):\n",
    "    \"\"\"\n",
    "    Find the positions within the suffix array sa of the longest possible suffix of p \n",
    "    that is a substring of s (the original string).\n",
    "    \n",
    "    Note that such positions must be consecutive, so we want the range of positions.\n",
    "\n",
    "    Input:\n",
    "        p: the pattern string\n",
    "        M, occ: buckets and repeats information used by sp, ep\n",
    "\n",
    "    Output: a tuple (range, length)\n",
    "        range: a tuple (start inclusive, end exclusive) of the indices in sa that contains\n",
    "            the longest suffix of p as a prefix. range=None if no indices matches any suffix of p\n",
    "        length: length of the longest suffix of p found in s. length=0 if no indices matches any suffix of p\n",
    "\n",
    "        An example return value would be ((2, 5), 7). This means that p[len(p) - 7 : len(p)] is\n",
    "        found in s and matches positions 2, 3, and 4 in the suffix array.\n",
    "\n",
    "    >>> s = 'ACGT' * 10 + '$'\n",
    "    >>> sa = get_suffix_array(s)\n",
    "    >>> sa\n",
    "    [40, 36, 32, 28, 24, 20, 16, 12, 8, 4, 0, 37, 33, 29, 25, 21, 17, 13, 9, 5, 1, 38, 34, 30, 26, 22, 18, 14, 10, 6, 2, 39, 35, 31, 27, 23, 19, 15, 11, 7, 3]\n",
    "    >>> L = get_bwt(s, sa)\n",
    "    >>> L\n",
    "    'TTTTTTTTTT$AAAAAAAAAACCCCCCCCCCGGGGGGGGGG'\n",
    "    >>> F = get_F(L)\n",
    "    >>> F\n",
    "    '$AAAAAAAAAACCCCCCCCCCGGGGGGGGGGTTTTTTTTTT'\n",
    "    >>> M = get_M(F)\n",
    "    >>> sorted(M.items())\n",
    "    [('$', 0), ('A', 1), ('C', 11), ('G', 21), ('T', 31)]\n",
    "    >>> occ = get_occ(L)\n",
    "    >>> type(occ) == dict, type(occ['$']) == list, type(occ['$'][0]) == int\n",
    "    (True, True, True)\n",
    "    >>> occ['$']\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    >>> exact_suffix_matches('ACTGA', M, occ)\n",
    "    ((1, 11), 1)\n",
    "    >>> exact_suffix_matches('$', M, occ)\n",
    "    ((0, 1), 1)\n",
    "    >>> exact_suffix_matches('AA', M, occ)\n",
    "    ((1, 11), 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize sp, ep\n",
    "    length = len(p)\n",
    "    last_char = p[-1]\n",
    "    sp = M[last_char]\n",
    "    if sp == -1:\n",
    "        return (None, 0)\n",
    "    \n",
    "    # find next(last_char)\n",
    "    nxt = float('inf')\n",
    "    nxt_item = None\n",
    "    for item in M:\n",
    "        if nxt > M[item] > M[last_char] and item != last_char:\n",
    "            nxt = M[item]\n",
    "            nxt_item = item\n",
    "    if nxt_item == None:\n",
    "        ep = length - 1\n",
    "    else:\n",
    "        ep = nxt - 1\n",
    "    \n",
    "    # changed for loop a bit, only works on strings len >= 2\n",
    "    # for strings of len 1, it skips to the end and works\n",
    "    for i in range(length-2,-1,-1):\n",
    "        sp_ph = M[p[i]] + occ[p[i]][sp-1]\n",
    "        ep_ph = M[p[i]] + occ[p[i]][ep]-1\n",
    "        print(p[i], sp_ph, ep_ph, M, occ)\n",
    "        if sp_ph > ep_ph:\n",
    "            return ((sp,ep+1),length-i-1)\n",
    "        sp = sp_ph\n",
    "        ep = ep_ph\n",
    "    return ((sp,ep+1), length)\n",
    "\n",
    "MIN_INTRON_SIZE = 20\n",
    "MAX_INTRON_SIZE = 10000\n",
    "\n",
    "class Aligner: \n",
    "    def __init__(self, genome_sequence, known_genes):\n",
    "        \"\"\"\n",
    "        Initializes the aligner. Do all time intensive set up here. i.e. build suffix array.\n",
    "\n",
    "        genome_sequence: a string (NOT TERMINATED BY '$') representing the bases of the of the genome\n",
    "        known_genes: a python set of Gene objects (see shared.py) that represent known genes. You can get the isoforms \n",
    "                     and exons from a Gene object\n",
    "\n",
    "        Time limit: 500 seconds maximum on the provided data. Note that our server is probably faster than your machine, \n",
    "                    so don't stress if you are close. Server is 1.25 times faster than the i7 CPU on my computer\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def align(self, read_sequence):\n",
    "        \"\"\"\n",
    "        Returns an alignment to the genome sequence. An alignment is a list of pieces. \n",
    "        Each piece consists of a start index in the read, a start index in the genome, and a length \n",
    "        indicating how many bases are aligned in this piece. Note that mismatches are count as \"aligned\".\n",
    "\n",
    "        Note that <read_start_2> >= <read_start_1> + <length_1>. If your algorithm produces an alignment that \n",
    "        violates this, we will remove pieces from your alignment arbitrarily until consecutive pieces \n",
    "        satisfy <read_start_2> >= <read_start_1> + <length_1>\n",
    "\n",
    "        Return value must be in the form (also see the project pdf):\n",
    "        [(<read_start_1>, <reference_start_1, length_1), (<read_start_2>, <reference_start_2, length_2), ...]\n",
    "\n",
    "        If no good matches are found: return the best match you can find or return []\n",
    "\n",
    "        Time limit: 0.5 seconds per read on average on the provided data.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'GTCGTGCGTCGTCGATAGTAGCTAGTCGTACGTCGTCGATAGCTCGATAGATGACTGTACGTAC$'\n",
    "sa = get_suffix_array(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CTTTGTTTTTGGGGATTTATTTAGTGGATCCCATAACTCACCACC$CGGGAGAACCGGGGGGAGC'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = get_bwt(s, sa)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$AAAAAAAAAAAAACCCCCCCCCCCCCCGGGGGGGGGGGGGGGGGGGTTTTTTTTTTTTTTTTTT'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F = get_F(L)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$': 0, 'A': 1, 'C': 14, 'G': 28, 'T': 47}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = get_M(F)\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'A': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13],\n",
       " 'C': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  13,\n",
       "  14],\n",
       " 'G': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  6,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  19,\n",
       "  19],\n",
       " 'T': [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  14,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18,\n",
       "  18]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occ = get_occ(L)\n",
    "occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CTTTGTTTTTGGGGATTTATTTAGTGGATCCCATAACTCACCACC$CGGGAGAACCGGGGGGAGC'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_try = construct_L(M, occ)\n",
    "L_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 14), 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact_suffix_matches('A', M, occ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
